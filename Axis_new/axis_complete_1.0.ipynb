{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import tabula\n",
    "import camelot\n",
    "import pdfminer\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "try:\n",
    "    from cStringIO import StringIO\n",
    "except ImportError:\n",
    "    from io import StringIO \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: No tables found in table area 1 [stream.py:361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column length is 7\n",
      "\n",
      "Diiferent structure on page: 0\n",
      "\n",
      "Diiferent structure on page: 6\n",
      "\n",
      "Diiferent structure on page: 7\n",
      "1st attempt\n",
      "list1\n",
      "backfill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mudracircle\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\indexing.py:576: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n",
      "c:\\users\\mudracircle\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\users\\mudracircle\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed_completed\n",
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "def abc(a):\n",
    "    if type(a) ==str:\n",
    "        if len(a.split(' '))==2:\n",
    "            z=a.split(' ')[1]\n",
    "        else:\n",
    "            z=a.split(' ')[0]\n",
    "    else :\n",
    "        z=a\n",
    "    return z\n",
    "\n",
    "def isnan(value):\n",
    "    try:\n",
    "        return math.isnan(float(value))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def backfill(df, narr):\n",
    "    print(\"backfill\")\n",
    "    df = df[pd.notnull(df[narr])]\n",
    "    df.iloc[:,-1]=df.iloc[:,-1].fillna(df.iloc[:,-2])\n",
    "    \n",
    "    try:\n",
    "        bal=[c for c in df.columns if \"BALANCE\" in str(c).upper()][0]\n",
    "        df[bal]=df[bal].apply(lambda x: abc(x))\n",
    "    except:\n",
    "        print(\"\\nBalance Column Missing\")\n",
    "        \n",
    "    df[\"flag\"]=df.iloc[:,-1].shift(1)\n",
    "    df=df[~df.index.isin(df[df.iloc[:,-1]==df.iloc[:,-2]].index)]\n",
    "\n",
    "    df=df.T.drop_duplicates().T\n",
    "    df[bal]=df[bal].apply(lambda x: str(x).replace(\",\",\"\").replace(\"(Cr)\",\"\").replace(\"(Dr)\",\"\")).astype(float)\n",
    "    df[\"flag\"]=df.iloc[:,0].astype(str)+df[bal].astype(str)\n",
    "    df[\"flag2\"]=np.arange(len(df))\n",
    "\n",
    "    df.loc[df[[\"flag\"]].duplicated(keep=False), 'flag'] = df[\"flag\"]+df[\"flag2\"].astype(str)\n",
    "    df['flag']=df['flag'].apply(lambda row : np.nan if 'nannan' in row else row).fillna(method='bfill')\n",
    "\n",
    "    df[narr]=df.groupby('flag')[narr].transform(lambda x:''.join(x))\n",
    "    df=df.drop_duplicates(['flag'],keep='last').iloc[0:,:-2].reset_index(drop=True)\n",
    "    df.to_csv(\"parsed_completed.csv\",index=0)\n",
    "    print(\"parsed_completed\")\n",
    "\n",
    "def proceed(df):\n",
    "    try:\n",
    "        idx=[ c for c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "        df.columns=df.iloc[idx] ; df=df.iloc[idx+1:,:] ; df.reset_index(drop=True,inplace=True)\n",
    "        print(\"1st attempt\")\n",
    "    except:\n",
    "        try:\n",
    "            idx=[ c for c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in df[df.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "            df.columns=df.iloc[idx] ; df=df.iloc[idx+1:,:] ; df.reset_index(drop=True,inplace=True)           \n",
    "        except:\n",
    "            print(\"\\nAxis-Column headers missing\"); pass\n",
    "\n",
    "    try:\n",
    "        df = df.drop([\"Init.\"], axis=1)\n",
    "    except:\n",
    "        try:\n",
    "            df = df.drop([\"Branch Name\"], axis=1)\n",
    "        except:pass\n",
    "\n",
    "    df=df[~df.index.isin(df[df.apply(lambda row: row.astype(str).str.lower().str.contains('opening balance|transaction total|closing balance|particulars|transaction').any(), axis=1) ==True].index)]\n",
    "    #df.drop(df.nunique(dropna=False)[(df.nunique(dropna=False) == 1)].index, axis=1,inplace=True)\n",
    "\n",
    "    try:\n",
    "        narr=[n for n in df.columns if \"PARTICULARS\" in str(n).upper()][0]\n",
    "    except:\n",
    "        try:\n",
    "            narr=[n for n in df.columns if \"NARRATION\" in str(n).upper()][0]\n",
    "        except:\n",
    "            try:\n",
    "                narr=[n for n in df.columns if \"DESCRIPTION\" in str(n).upper()][0] \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    list1 = ['Tran Date','Chq No','Particulars','Debit','Credit','Balance']\n",
    "    list2 = ['Tran Date','Value Date','Transaction Particulars','Chq No','Amount(INR)','DR/CR','Balance(INR)']\n",
    "    list3 = ['Tran Date','Value Date','Transaction Particulars','Chq No.','Amount','DR|CR','Balance']\n",
    "\n",
    "    if list(df.columns.values) == list1 :\n",
    "        print(\"list1\")\n",
    "        backfill(df,narr)\n",
    "        \n",
    "    elif list(df.columns.values) == list2 :\n",
    "        print(\"list2\")\n",
    "        backfill(df,narr)\n",
    "\n",
    "    elif list(df.columns.values) == list3:\n",
    "        print(\"list3\")   \n",
    "        \n",
    "        try:\n",
    "            bal=[c for c in df.columns if \"BALANCE\" in str(c).upper()][0]\n",
    "            df[bal]=df[bal].apply(lambda x: abc(x))\n",
    "        except:\n",
    "            print(\"\\nBalance Column Missing\")\n",
    "\n",
    "        try:    \n",
    "            df.replace(r'^\\s*$', np.nan, regex=True, inplace = True)\n",
    "            #type(df[\"Transaction Particulars\"][15])\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            df.dropna(axis=0, how='all',inplace=True)\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            df.reset_index(drop=True,inplace=True)\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            for j,i in enumerate(df[\"Transaction Particulars\"]):\n",
    "                if isnan(i) == True:\n",
    "                    df[narr][j] = df[narr][j-1]+df[narr][j+1]\n",
    "                else:\n",
    "                    pass\n",
    "        except:pass\n",
    "\n",
    "        try:\n",
    "            df.dropna(subset=['Tran Date'], inplace = True)\n",
    "        except:\n",
    "            try:\n",
    "                df.dropna(subset=['Value Date'], inplace = True)\n",
    "            except:pass\n",
    "\n",
    "        df.to_csv(\"parsed_completed.csv\",index=0)\n",
    "        print(\"parsed_completed\")\n",
    "        \n",
    "    else:\n",
    "        print(\"In Proceed, Another pattern found\")\n",
    "\n",
    "def came(f):\n",
    "    tables = camelot.read_pdf(f, flavor='stream', pages='1,2', edge_tol=500)\n",
    "    if len(tables) != 0:\n",
    "        dt=pd.DataFrame(); tmp=pd.DataFrame()\n",
    "        first_check = tables[0].df; second_check = tables[1].df;\n",
    "        # print(first_check.shape[1])\n",
    "        # print(second_check.shape[1])\n",
    "        if (first_check.shape[1] > 5):\n",
    "            try:\n",
    "                idx=[ c for c in first_check[first_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in first_check[first_check.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                first_check.columns=first_check.iloc[idx]\n",
    "            except:\n",
    "                try:\n",
    "                    idx=[ c for c in first_check[first_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in dt[dt.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                    first_check.columns=first_check.iloc[idx]\n",
    "                except:\n",
    "                    print(\"\\nAxis-Column headers missing\")\n",
    "            tables2 = camelot.read_pdf(f, flavor='stream', pages='all', edge_tol=500)\n",
    "            print(\"\\nlength of first_check:\",len(first_check.columns))\n",
    "            if len(first_check.columns) == 7:\n",
    "                print(\"Column length is 7\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df\n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 6):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[6] = np.nan; tmp = tmp[[0,6,1,2,3,4,5]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "\n",
    "            elif len(first_check.columns) == 8:\n",
    "                print(\"Column length is 8\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df   \n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 8):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[7] = np.nan; tmp = tmp[[0,1,2,7,3,4,5,6]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "            elif len(first_check.columns) > 8:\n",
    "                print(\"Column length greater than 8\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df \n",
    "                    if (tmp.shape[1] > 8):\n",
    "                        try:\n",
    "                            idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                            tmp.columns=tmp.iloc[idx] ; tmp=tmp.iloc[idx:,:] ; tmp.reset_index(drop=True,inplace=True)\n",
    "                        except:\n",
    "                            try:\n",
    "                                idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                                tmp.columns=tmp.iloc[idx] ; tmp=tmp.iloc[idx:,:] ; tmp.reset_index(drop=True,inplace=True)           \n",
    "                            except:\n",
    "                                print(\"\\nAxis-Column headers missing\"); pass\n",
    "                        tmp.drop(\"\",axis = 1,inplace = True)\n",
    "                        tmp.columns = [0,1,2,3,4,5,6,7]\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        # print(\"\\n\",tmp)\n",
    "                        dt=pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 8):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        # print(\"\\n\",tmp)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[7] = np.nan; tmp = tmp[[0,1,2,7,3,4,5,6]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        # print(\"\\n\",tmp)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 6):\n",
    "                        try:\n",
    "                            idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                        except:\n",
    "                            try:\n",
    "                                idx=[ c for c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                            except:\n",
    "                                print(\"\\nAxis-Column headers missing\")\n",
    "                        tmp.columns=tmp.iloc[idx] ; tmp=tmp.iloc[idx+1:,:] ; tmp.reset_index(drop=True,inplace=True) \n",
    "                        tmp=tmp[~tmp.index.isin(tmp[tmp.apply(lambda row: row.astype(str).str.lower().str.contains('page:|account status|total|reason for return|inward clg|opening balance|statement of a/c').any(), axis=1) ==True].index)]\n",
    "                        if tmp.columns[0] == 'Tran Date\\nValue Date\\nTransaction Particulars':\n",
    "                            tmp.columns = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\"]\n",
    "                            tmp.reset_index(drop = True, inplace=True)\n",
    "                            tmp1 = pd.DataFrame(tmp.A.str.split('\\n',2).tolist(),columns=[\"Z1\", \"Z2\", \"Z3\"])\n",
    "                            result = pd.concat([tmp1, tmp], axis=1, sort=False)\n",
    "                            result.drop('A' ,axis=1, inplace=True)\n",
    "                            result[\"Y\"] = result[\"Z1\"]\n",
    "                            for i,j in enumerate(result[\"Y\"]):\n",
    "                                if re.search(r'(\\d+-\\d+-\\d+)',j):\n",
    "                                    result.at[i, 'Y'] = \"\"\n",
    "                                    pass\n",
    "                                elif re.search(r'^\\s*$',j):\n",
    "                                    result.at[i, 'Y'] = \"\"\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    pass\n",
    "                                    \n",
    "                            for i,j in enumerate(result[\"Z1\"]):\n",
    "                                if re.search(r'(\\d+-\\d+-\\d+)',j):\n",
    "                                    pass\n",
    "                                elif re.search(r'^\\s*$',j):\n",
    "                                    result.at[i, 'Z1'] = \"\"\n",
    "                                    pass\n",
    "                                else:\n",
    "                                    result.at[i, 'Z1'] = \"\"\n",
    "                                    pass \n",
    "                            result.fillna(value=pd.np.nan, inplace=True)\n",
    "                            result['X'] = result['Z3'].fillna('') + result['Y'].fillna('')\n",
    "                            result.drop(['Z3','Y'] ,axis=1, inplace=True)\n",
    "                            result = result[['Z1', 'Z2', 'X', 'B', 'C','D','E','F']]\n",
    "                            result.columns = [0,1,2,3,4,5,6,7]\n",
    "                            result=pd.DataFrame(result).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                            # print(\"\\n\",result)\n",
    "                            dt=pd.concat([dt,result]).reset_index(drop=True)\n",
    "                        else:\n",
    "                            print(\"\\nIn without box pdf another Structure on page:\",i); pass\n",
    "\n",
    "        elif(second_check.shape[1] > 5):\n",
    "            try:\n",
    "                idx=[ c for c in second_check[second_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in second_check[second_check.apply(lambda row: row.astype(str).str.lower().str.contains('date').any(), axis=1) ==True].index ][0]\n",
    "                second_check.columns=second_check.iloc[idx]\n",
    "            except:\n",
    "                try:\n",
    "                    idx=[ c for c in second_check[second_check.apply(lambda row: row.astype(str).str.lower().str.contains('balance').any(), axis=1) ==True].index if c in dt[dt.apply(lambda row: row.astype(str).str.lower().str.contains('particular').any(), axis=1) ==True].index ][0]\n",
    "                    second_check.columns=second_check.iloc[idx]\n",
    "                except:\n",
    "                    print(\"\\nAxis-Column headers missing\")\n",
    "            tables2 = camelot.read_pdf(f, flavor='stream', pages='all', edge_til=500)\n",
    "            if len(second_check.columns) == 7:\n",
    "                print(\"Column length is 7\")\n",
    "                for i in range(len(tables2)):\n",
    "                    tmp=tables2[i].df\n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 6):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[6] = np.nan; tmp = tmp[[0,6,1,2,3,4,5]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "\n",
    "            elif len(second_check.columns) == 8:\n",
    "                print(\"Column length is 8\")\n",
    "                for i in range(len(tables2)):\n",
    "                    #print(\"\\n\",i,\":\",tmp.shape[1])\n",
    "                    tmp=tables2[i].df\n",
    "                    if (tmp.shape[1] < 5):\n",
    "                        print(\"\\nDiiferent structure on page:\",i); pass\n",
    "                    elif (tmp.shape[1] == 8):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    elif (tmp.shape[1] == 7):\n",
    "                        tmp=pd.DataFrame(tmp).replace(r'^\\s*$', np.nan, regex=True)\n",
    "                        tmp[7] = np.nan; tmp = tmp[[0,1,2,7,3,4,5,6]]; tmp.columns = range(tmp.shape[1]);\n",
    "                        dt = pd.concat([dt,tmp]).reset_index(drop=True)\n",
    "                    else:\n",
    "                        print(\"\\nAnother Structure on page:\",i); pass\n",
    "\n",
    "    else:\n",
    "        print(\"\\nLength of table is 0\"); pass   \n",
    "    return dt\n",
    "\n",
    "try:\n",
    "    f = r'C:\\Users\\MudraCircle\\Desktop\\bks_raw\\Parsing_testing\\Axis_new\\files\\axis07.pdf'\n",
    "    try:\n",
    "        df = came(f); df = proceed(df);\n",
    "        print(\"Completed.\")\n",
    "    except:\n",
    "        print(\"Not parsed\")\n",
    "        pass\n",
    "except:\n",
    "    print(\"\\n Can't parse\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
